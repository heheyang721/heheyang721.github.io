<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>基于pytorch的LSTM多维序列预测</title>
      <link href="/2022/10/11/LSTM/"/>
      <url>/2022/10/11/LSTM/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​         羊最近碰到了多维度的时间序列问题，经过我一番查资料发现解决这类问题往上大多数为两类方法，一种是以ARIMAX为代表的自回归时间序列模型，通过对序列数据自回归，得到数据的时序趋势特征，进而实现时间序列预测。但是在我查看的所有样例中，几乎都是针对单维数据建构的，我没有找到一种兼容多维数据的自回归方法，如果大家有好的方法推荐，欢迎和我交流。</p><p>​        所以这时候我把目光转向第二种办法——深度学习，当然有一定基础的我（有点基础，但是不多），不会整原始的循环神经网络RNN，因为普通的RNN很难训练的，其在实际应用中，很难处理长距离的依赖。我把目标转向长短期记忆网络LSTM，话不多说，开整！</p><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>​        已知一段时间某个地区的空气污染质量指标，其中包括’aqi’, ‘pm2_5’, ‘pm10’, ‘so2’, ‘no2’, ‘co’, ‘o3’相关指标，根据现有的数据构建LSTM预测未来24小时内的空气污染质量指标。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><ol><li>数据准备</li></ol><p>​        数据准备作为模型构建的基础，也是本人code最长时间的部分，不同数据的数据处理不同，有点基础的我按照传统逻辑进行数据准备，主要包括：获取数据，数据清洗，数据标准化，滑窗取样，数据分割，数据集生成。</p><p>​        tips：这里的一些处理步骤名词，有的可能只是我个人理解说的词，如果您有更加专业的可以和我交流，主页有邮箱呦。</p><p>​        代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_path</span>(<span class="params">path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    获取数据路径</span></span><br><span class="line"><span class="string">    :param path:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    files = os.listdir(path)</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;气象&quot;</span> <span class="keyword">in</span> file:</span><br><span class="line">            df_weather = pd.read_excel(os.path.join(path,file))</span><br><span class="line">        <span class="keyword">elif</span> <span class="string">&quot;空气质量&quot;</span> <span class="keyword">in</span> file:</span><br><span class="line">            df_air = pd.read_excel(os.path.join(path,file))</span><br><span class="line">    df = pd.merge(df_air, df_weather, on=[<span class="string">&quot;time&quot;</span>, <span class="string">&quot;cityname&quot;</span>])</span><br><span class="line">    df = df[df[<span class="string">&quot;cityname&quot;</span>] == <span class="string">&quot;许昌&quot;</span>]</span><br><span class="line">    df.to_excel(os.path.join(path, path+<span class="string">&quot;.xlsx&quot;</span>), index=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> os.path.join(path, path+<span class="string">&quot;.xlsx&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>(<span class="params">path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    获取数据</span></span><br><span class="line"><span class="string">    :param path:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    df = pd.read_excel(path)</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_process</span>(<span class="params">df</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    数据清洗</span></span><br><span class="line"><span class="string">    :param df:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 删除city_name</span></span><br><span class="line">    columns = <span class="built_in">list</span>(df.columns)</span><br><span class="line">    columns.remove(<span class="string">&quot;cityname&quot;</span>)</span><br><span class="line">    df = df.loc[:,columns]</span><br><span class="line">    df.set_index(<span class="string">&quot;time&quot;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># wind one-hot编码</span></span><br><span class="line">    df = pd.get_dummies(df,prefix=<span class="string">&quot;winddirection&quot;</span>)</span><br><span class="line">    <span class="comment"># 缺失值删除</span></span><br><span class="line">    df = df.dropna(axis=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 获取label</span></span><br><span class="line">    label = df.loc[:,[<span class="string">&#x27;aqi&#x27;</span>, <span class="string">&#x27;pm2_5&#x27;</span>, <span class="string">&#x27;pm10&#x27;</span>, <span class="string">&#x27;so2&#x27;</span>, <span class="string">&#x27;no2&#x27;</span>, <span class="string">&#x27;co&#x27;</span>, <span class="string">&#x27;o3&#x27;</span>]]</span><br><span class="line">    <span class="keyword">return</span> df,label</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalization</span>(<span class="params">data,label</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    标准化</span></span><br><span class="line"><span class="string">    :param data:</span></span><br><span class="line"><span class="string">    :param label:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    mm_x = MinMaxScaler()</span><br><span class="line">    mm_y = MinMaxScaler()</span><br><span class="line">    data = data.values</span><br><span class="line">    data = mm_x.fit_transform(data)</span><br><span class="line">    label = mm_y.fit_transform(label)</span><br><span class="line">    <span class="built_in">print</span>(label.shape)</span><br><span class="line">    <span class="keyword">return</span> data, label, mm_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sliding_windows</span>(<span class="params">data,label,seq_length,time_seq</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    构建训练数据，LSTM的x,y</span></span><br><span class="line"><span class="string">    :param data:</span></span><br><span class="line"><span class="string">    :param seq_length:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = []</span><br><span class="line">    y = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data) - seq_length - time_seq):</span><br><span class="line">        _x = data[i:(i + seq_length), :]</span><br><span class="line">        _y = label[(i+seq_length):(i+seq_length+time_seq),:]</span><br><span class="line">        _y = np.array(_y).flatten().tolist()</span><br><span class="line">        x.append(_x)</span><br><span class="line">        y.append(_y)</span><br><span class="line">    x, y = np.array(x), np.array(y)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_split</span>(<span class="params">x, y, split_ratio</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    数据分割</span></span><br><span class="line"><span class="string">    :param x:</span></span><br><span class="line"><span class="string">    :param y:</span></span><br><span class="line"><span class="string">    :param split_ratio:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(y) * split_ratio)</span><br><span class="line">    test_size = <span class="built_in">len</span>(y) - train_size</span><br><span class="line"></span><br><span class="line">    x_data = Variable(torch.Tensor(np.array(x)))</span><br><span class="line">    y_data = Variable(torch.Tensor(np.array(y)))</span><br><span class="line"></span><br><span class="line">    x_train = Variable(torch.Tensor(np.array(x[<span class="number">0</span>:train_size])))</span><br><span class="line">    y_train = Variable(torch.Tensor(np.array(y[<span class="number">0</span>:train_size])))</span><br><span class="line">    x_test = Variable(torch.Tensor(np.array(x[train_size:<span class="built_in">len</span>(x)])))</span><br><span class="line">    y_test = Variable(torch.Tensor(np.array(y[train_size:<span class="built_in">len</span>(y)])))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;x_train.shape,y_train.shape,x_test.shape,y_test.shape:\n&#x27;</span>, x_train.shape, y_train.shape, x_test.shape,</span><br><span class="line">          y_test.shape)</span><br><span class="line">    <span class="keyword">return</span> x_data, y_data, x_train, y_train, x_test, y_test</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_generator</span>(<span class="params">x_train, y_train, x_test, y_test, n_iters, batch_size</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    数据生成</span></span><br><span class="line"><span class="string">    :param x_train:</span></span><br><span class="line"><span class="string">    :param y_train:</span></span><br><span class="line"><span class="string">    :param x_test:</span></span><br><span class="line"><span class="string">    :param y_test:</span></span><br><span class="line"><span class="string">    :param n_iters:</span></span><br><span class="line"><span class="string">    :param batch_size:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_epochs = n_iters / (<span class="built_in">len</span>(x_train) / batch_size)</span><br><span class="line">    num_epochs = <span class="built_in">int</span>(num_epochs)</span><br><span class="line">    train_dataset = Data.TensorDataset(x_train, y_train)</span><br><span class="line">    test_dataset = Data.TensorDataset(x_test, y_test)</span><br><span class="line">    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,</span><br><span class="line">                                               batch_size=batch_size,</span><br><span class="line">                                               shuffle=<span class="literal">False</span>)</span><br><span class="line">    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,</span><br><span class="line">                                              batch_size=batch_size,</span><br><span class="line">                                              shuffle=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> train_loader, test_loader, num_epochs</span><br></pre></td></tr></table></figure><ol start="2"><li>LSTM模型构建</li></ol><p>​        该部分就是构建LSTM的NET，参数包括输入大小 input_size，输出大小output_size，隐藏层大小hidden_size，网络层数num_layers，预测时长seq_length，主要是由LSTM层和全连接层构成，代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LSTM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, output_size, input_size, hidden_size, num_layers,seq_length</span>):</span><br><span class="line">        <span class="built_in">super</span>(LSTM, self).__init__()</span><br><span class="line">        self.num_classes = output_size</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.seq_length = seq_length</span><br><span class="line">        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,</span><br><span class="line">                            num_layers=num_layers, batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.fc = nn.Linear(hidden_size, output_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        h_0 = Variable(torch.zeros(</span><br><span class="line">            self.num_layers, x.size(<span class="number">0</span>), self.hidden_size))</span><br><span class="line">        c_0 = Variable(torch.zeros(</span><br><span class="line">            self.num_layers, x.size(<span class="number">0</span>), self.hidden_size))</span><br><span class="line">        <span class="comment"># Propagate input through LSTM</span></span><br><span class="line">        ula, (h_out, _) = self.lstm(x, (h_0, c_0))</span><br><span class="line">        h_out = h_out.view(-<span class="number">1</span>, self.hidden_size)</span><br><span class="line">        out = self.fc(h_out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><ol start="3"><li>模型训练及评价</li></ol><p>​        设定MSE损失函数，以及Adam优化器进行传播训练，并计算准确率以及相关系数进行评价，代码如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model_train</span>(<span class="params">num_epochs,train_loader,model,optimizer,criterion</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    模型训练</span></span><br><span class="line"><span class="string">    :param num_epochs:</span></span><br><span class="line"><span class="string">    :param train_loader:</span></span><br><span class="line"><span class="string">    :param model:</span></span><br><span class="line"><span class="string">    :param optimizer:</span></span><br><span class="line"><span class="string">    :param criterion:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Training</span></span><br><span class="line">    <span class="built_in">iter</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epochs <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> i, (batch_x, batch_y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">            outputs = model(batch_x)</span><br><span class="line">            <span class="comment"># clear the gradients</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            <span class="comment"># loss</span></span><br><span class="line">            loss = criterion(outputs, batch_y)</span><br><span class="line">            <span class="comment"># backpropagation</span></span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="built_in">iter</span> += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">iter</span> % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;iter: %d, loss: %1.5f&quot;</span> % (<span class="built_in">iter</span>, loss.item()))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_acc</span>(<span class="params">lst1,lst2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算准确率</span></span><br><span class="line"><span class="string">    :param lst1:</span></span><br><span class="line"><span class="string">    :param lst2:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lst1)):</span><br><span class="line">        <span class="keyword">if</span> lst1[i] &lt;= (lst2[i]*<span class="number">1.2</span>) <span class="keyword">and</span> lst1[i] &gt;= (lst2[i]*<span class="number">0.8</span>):</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count/<span class="built_in">len</span>(lst1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">result</span>(<span class="params">x_data, y_data, model, mm_y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    结果分析</span></span><br><span class="line"><span class="string">    :param x_data:</span></span><br><span class="line"><span class="string">    :param y_data:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    data_pre = model(x_data)</span><br><span class="line">    pre = data_pre.detach().numpy()</span><br><span class="line">    y = y_data.detach().numpy()</span><br><span class="line">    corr_scores = []</span><br><span class="line">    acc = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pre)):</span><br><span class="line">        s1 = pd.Series(pre[i])</span><br><span class="line">        s2 = pd.Series(y[i])</span><br><span class="line">        corr = s1.corr(s2)</span><br><span class="line">        corr_scores.append(corr)</span><br><span class="line">        count = count_acc(pre[i],y[i])</span><br><span class="line">        acc.append(count)</span><br><span class="line">    plt.plot(corr_scores)</span><br><span class="line">    plt.plot(acc)</span><br><span class="line">    plt.legend((<span class="string">&#x27;corr&#x27;</span>, <span class="string">&#x27;acc&#x27;</span>), fontsize=<span class="string">&#x27;15&#x27;</span>)</span><br><span class="line">    plt.savefig(<span class="string">&quot;corr_r2.png&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;#################model evaluate##################&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pearson score: %.4f&quot;</span> %np.mean(corr_scores))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;acc score: %.4f&quot;</span> %np.mean(acc))</span><br></pre></td></tr></table></figure><p>​        本人用自用电脑跑的，所以传播次数有限，最后得到相关结果如下：</p><p><img src="/2022/10/11/LSTM/result.png" alt="运行结果图"></p>]]></content>
      
      
      <categories>
          
          <category> lstm预测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> LSTM </tag>
            
            <tag> Prediction </tag>
            
            <tag> MultiSequence </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>macOS conda配置StanfordCoreNLP实现NER</title>
      <link href="/2022/09/04/stanfordcorenlp/"/>
      <url>/2022/09/04/stanfordcorenlp/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        不知道大家是不是和我使用macOS感受一样，装个库问题百出，网上教程还少，stanfordcorenlp就是这些刺头之一，虽然麻烦但是通过努力也算是成功实现了我起初的目的，在此记录一下。</p><p>​        首先介绍一下stanfordcorenlp，它是一个自然语言处理工具包，其集成了很多非常实用的功能，包括分词，词性标注，句法分析等等。它就是把训练好的模型封装起来，方便大家的使用，实际上可以类比为一个软件。目前市面上有不少类似的工具，结巴分词、清华、哈工大等等。</p><p>​        那么我为什么选择stanfordcorenlp呢？理由网上给了三点，我给出一点：</p><ol><li><p>功能足够多，一站式解决所有主流需求；</p></li><li><p>操作足够方便，放到 Python 里基本上就是一两行代码；</p></li><li><p>语言支持广泛，目前支持阿拉伯语，中文，英文，法语，德语，西班牙语，做平行语料的对比非常方便；</p></li><li><p>我自身体验下来，最后关键一点，运行快。</p></li></ol><h2 id="个人电脑配置"><a href="#个人电脑配置" class="headerlink" title="个人电脑配置"></a>个人电脑配置</h2><ol><li>系统：macOS Monterey</li><li>conda环境，python3.9</li><li>java version “17.0.2”，无java环境需提前配置java环境</li></ol><h2 id="配置步骤"><a href="#配置步骤" class="headerlink" title="配置步骤"></a>配置步骤</h2><ol><li>安装stanfordcorenlp库</li></ol><p>​        这里通过实测，推荐使用pip进行安装，虚拟环境没有pip的先安装pip，安装代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install stanfordcorenlp==3.8.0.1</span><br></pre></td></tr></table></figure><p>​       一定要设置版本号，默认版本为3.9，在后续测试中存在问题，推荐3.8.0.1版本。安装成功后，在虚拟环境site-packages中存在stanfordcorenlp文件夹，其中包含一个corenlp.py文件，步骤4需要。</p><ol start="2"><li>下载StanfordCoreNLP文件及中文模型jar包</li></ol><p>​        前往官网下载两个文件，经过本人测试最新版本在后续配置中存在问题，这里推荐为3.9.0版本，版本发布日期为2018-01-31，并下载中文jar包，如下所示：</p><p><img src="https://s2.loli.net/2022/09/04/X1W9GialsgqjNE4.png" alt="下载界面.png"></p><p><a href="https://stanfordnlp.github.io/CoreNLP/history.html">CoreNLP文件及模型jar包下载地址</a></p><ol start="3"><li>配置文件</li></ol><p>​       两个文件下载好后，你将得到两个文件，stanford-corenlp-full-2018-01-31.zip以及stanford-chinese-corenlp-2018-01-31-models.jar，对于zip文件需要解压放入任意文件夹，然后把模型jar包放入解压后的stanford-corenlp-full-2018-01-31文件夹中。</p><ol start="4"><li>代码实现NER</li></ol><p>​        以上StanfordCoreNLP算是配置好了，这个时候我们还需要去步骤1中的corenlp.py文件中84，85行代码注释掉，如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check if the port is in use</span></span><br><span class="line"><span class="keyword">if</span> self.port <span class="keyword">in</span> [conn.laddr[<span class="number">1</span>] <span class="keyword">for</span> conn <span class="keyword">in</span> psutil.net_connections()]:</span><br><span class="line">    <span class="keyword">raise</span> IOError(<span class="string">&#x27;Port &#x27;</span> + <span class="built_in">str</span>(self.port) + <span class="string">&#x27; is already in use.&#x27;</span>)</span><br></pre></td></tr></table></figure><p>​       以上就可以实现NER了测试demo如下</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> stanfordcorenlp <span class="keyword">import</span> StanfordCoreNLP</span><br><span class="line"><span class="comment"># 修改stanford-corenlp-full-2018-01-31所在的path，port一定要写</span></span><br><span class="line">zh_model = StanfordCoreNLP(<span class="string">r&#x27;/your_path/stanford-corenlp-full-2018-01-31&#x27;</span>, lang=<span class="string">&#x27;zh&#x27;</span>,port=<span class="number">9999</span>)</span><br><span class="line">sentence = <span class="string">&quot;我在福建，我爱中国&quot;</span></span><br><span class="line"><span class="comment"># 分词</span></span><br><span class="line"><span class="built_in">print</span>(zh_model.word_tokenize(sentence))</span><br><span class="line"><span class="comment"># 词性标注</span></span><br><span class="line"><span class="built_in">print</span>(zh_model.pos_tag(sentence))</span><br><span class="line"><span class="comment"># NER</span></span><br><span class="line"><span class="built_in">print</span>(zh_model.ner(sentence))</span><br></pre></td></tr></table></figure><p>​        结果如下图所示：</p><p><img src="https://s2.loli.net/2022/09/04/gnGdpUHBQtcIT3K.png" alt="截屏2022-09-04 23.53.53.png"></p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>​        该博客为个人学习使用，欢迎大家在主页关注我的git-hub，欢迎大家多多交流关注，如有问题欢迎邮件！</p><p><img src="https://s2.loli.net/2022/09/05/lC4RcV3pZDEh8Ff.png" alt="截屏2022-09-04 23.59.18.png"></p>]]></content>
      
      
      <categories>
          
          <category> conda配置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> macOS </tag>
            
            <tag> conda </tag>
            
            <tag> NER </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>helloworld</title>
      <link href="/2022/08/28/helloworld/"/>
      <url>/2022/08/28/helloworld/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
